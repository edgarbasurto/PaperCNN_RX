% This file was created with JabRef 2.10.
% Encoding: Cp1252

%
%@Article{2,
%  Title                    = {{Compensaci{\'{o}}n de los Efectos Generados en la Imagen por el Control de Navegaci{\'{o}}n del Robot Aibo ERS 7}},
%  Author                   = {Aguilar, Wilbert and Angulo, Cecilio},
%  Journal                  = {Memorias del VII Congreso de Ciencia y Tecnolog{\'{i}}a ESPE 2012},
%  Year                     = {2012},
%  Number                   = {JUNE},
%  Pages                    = {165--170},
%
%  Doi                      = {10.13140/2.1.3438.2089},
%  File                     = {:C$\backslash$:/Users/UPS/Desktop/mobile{\_}robot/3{\_}Compensacion{\_}y{\_}Aprendizaje{\_}de{\_}Efectos{\_}Ge.pdf:pdf},
%  ISBN                     = {9788461573981},
%  ISSN                     = {1390-4663},
%  Keywords                 = {(),como objetivo dise{\~{n}}ar una,de im{\'{a}}genes,el presente trabajo tiene,estimaci{\'{o}}n del error,geometr{\'{i}}a,im{\'{a}}genes,matching,reconocimiento de objetos,reconstrucci{\'{o}}n de,transformaciones,visi{\'{o}}n},
%  Owner                    = {UPS},
%  Timestamp                = {2016.12.27}
%}
%
%@Article{3,
%  Title                    = {{Compensaci{\'{o}}n y Aprendizaje de Efectos Generados en la Imagen durante el Desplazamiento de un Robot}},
%  Author                   = {Aguilar, Wilbert and Angulo, Cecilio},
%  Journal                  = {X Simposio CEA Ingenier{\'{i}}a de Control 1,2 Marzo, 2012},
%  Year                     = {2012},
%  Pages                    = {165--170},
%
%  Doi                      = {10.13140/2.1.3438.2089},
%  File                     = {:C$\backslash$:/Users/UPS/Desktop/mobile{\_}robot/3{\_}Compensacion{\_}y{\_}Aprendizaje{\_}de{\_}Efectos{\_}Ge.pdf:pdf},
%  ISBN                     = {9788461573981},
%  ISSN                     = {1390-4663},
%  Keywords                 = {(),como objetivo dise{\~{n}}ar una,de im{\'{a}}genes,el presente trabajo tiene,estimaci{\'{o}}n del error,geometr{\'{i}}a,im{\'{a}}genes,matching,reconocimiento de objetos,reconstrucci{\'{o}}n de,transformaciones,visi{\'{o}}n},
%  Owner                    = {UPS},
%  Timestamp                = {2016.12.27}
%}
%
%@Article{7,
%  Title                    = {{3D Environment Mapping Using the Kinect V2 and Path Planning Based on RRT Algorithms}},
%  Author                   = {Aguilar, Wilbert and Morales, Stephanie},
%  Journal                  = {Electronics},
%  Year                     = {2016},
%  Number                   = {4},
%  Pages                    = {70},
%  Volume                   = {5},
%
%  Abstract                 = {This paper describes a 3D path planning system that is able to provide a solution trajectory for the automatic control of a robot. The proposed system uses a point cloud obtained from the robot workspace,with a Kinect V2 sensor to identify the interest regions and the obstacles of the environment. Our proposal includes a collision-free path planner based on the Rapidly-exploring Random Trees variant (RRT*),for a safe and optimal navigation of robots in 3D spaces. Results on RGB-D segmentation and recognition,point cloud processing,and comparisons between different RRT* algorithms,are presented.},
%  Doi                      = {10.3390/electronics5040070},
%  File                     = {:C$\backslash$:/Users/UPS/Desktop/mobile{\_}robot/7{\_}3D Environment Mapping Using the Kinect.pdf:pdf},
%  ISSN                     = {2079-9292},
%  Keywords                 = {3d modeling,computational geometry,mobile robotics,path planning,point cloud registration,rgb-d,rrt,segmentation},
%  Owner                    = {UPS},
%  Timestamp                = {2016.12.27}
%}
%
%@Article{8,
%  Title                    = {{Estabilizaci{\'{o}}n de v{\'{i}}deo en micro veh{\'{i}}culos a{\'{e}}reos y su aplicaci{\'{o}}n en la detecci{\'{o}}n de caras}},
%  Author                   = {Aguilar, Wilbert G and Angulo, Cecilio},
%  Year                     = {2014},
%  Pages                    = {155--160},
%
%  File                     = {:C$\backslash$:/Users/UPS/Desktop/mobile{\_}robot/8{\_}Estabilizaci{\'{o}}n de v{\'{i}}deo en micro veh{\'{i}}culos a{\'{e}}reos.pdf:pdf},
%  Keywords                 = {control,detecci{\'{o}}n,estabilizaci{\'{o}}n de video,filtro,intenci{\'{o}}n de,micro veh{\'{i}}culos a{\'{e}}reos,movimiento},
%  Owner                    = {UPS},
%  Timestamp                = {2016.12.27}
%}
%
%@Article{1,
%  Title                    = {{Vision-based intelligent vehicles: State of the art and perspectives}},
%  Author                   = {Bertozzi, Massimo and Broggi, Alberto and Fascioli, Alessandra},
%  Journal                  = {Robotics and Autonomous Systems},
%  Year                     = {2000},
%  Number                   = {1},
%  Pages                    = {1--16},
%  Volume                   = {32},
%
%  Abstract                 = {Recently, a large emphasis has been devoted to Automatic Vehicle Guidance since the automation of driving tasks carries a large number of benefits, such as the optimization of the use of transport infrastructures, the improvement of mobility, the minimization of risks, travel time, and energy consumption. This paper surveys the most common approaches to the challenging task of Autonomous Road Following reviewing the most promising experimental solutions and prototypes developed worldwide using AI techniques to perceive the environmental situation by means of artificial vision. The most interesting results and trends in this field as well as the perspectives on the evolution of intelligent vehicles in the next decades are also sketched out.},
%  Doi                      = {10.1016/S0921-8890(99)00125-6},
%  File                     = {:C$\backslash$:/Users/UPS/Desktop/mobile{\_}robot/1{\_}Vision-based intelligent vehicles State of the art and perspectives.pdf:pdf},
%  ISSN                     = {09218890},
%  Keywords                 = {automatic vehicle guidance,intelligent transportation systems,intelligent vehicles,its,machine vision},
%  Owner                    = {UPS},
%  Timestamp                = {2016.12.27}
%}
%
%@Article{5,
%  Title                    = {{Autonomous driving goes downtown}},
%  Author                   = {Franke, Uwe and Gavrila, Dariu and G{\"{o}}rzig, Steffen and Lindner, Frank and Paetzold, Frank and W{\"{o}}hler, Christian},
%  Journal                  = {IEEE Intelligent Systems and Their Applications},
%  Year                     = {1998},
%  Number                   = {6},
%  Pages                    = {40--48},
%  Volume                   = {13},
%
%  Abstract                 = {Most computer-vision systems for vehicle guidance are for highway scenarios. Developing autonomous or driver-assistance systems for complex urban traffic poses new algorithmic and system-architecture challenges. To address these issues, the authors introduce their intelligent Stop{\&}Go system and discuss appropriate algorithms and approaches for vision-module control},
%  Doi                      = {10.1109/5254.736001},
%  File                     = {:C$\backslash$:/Users/UPS/Desktop/mobile{\_}robot/5{\_}Autonomous driving goes downtown.pdf:pdf},
%  ISBN                     = {1094-7167 VO - 13},
%  ISSN                     = {10947167},
%  Owner                    = {UPS},
%  Timestamp                = {2016.12.27}
%}
%
%@Article{6,
%  Title                    = {{Fast stereo based object detection for stop{\&}go traffic}},
%  Author                   = {Franke, U. and Kutzbach, I.},
%  Journal                  = {IEEE Intelligent Vehicles Symposium},
%  Year                     = {1996},
%  Pages                    = {339--344},
%
%  Abstract                 = {This paper presents a new fast binocular stereo approach for the detection and tracking of objects, in particular for stop{\&}go traffic. The proposed scheme is based on a local feature extraction and detects dominant objects by means of a Hough transform like disparity grouping. It is able to handle not only vehicles, but also other objects such as pedestrians. In addition, it allows to determine the camera orientation relative to the road and to distinguish between road surface},
%  Doi                      = {10.1109/IVS.1996.566403},
%  File                     = {:C$\backslash$:/Users/UPS/Desktop/mobile{\_}robot/6{\_}Fast stereo based object detection for stop{\&}go traffic.pdf:pdf},
%  ISBN                     = {0-7803-3652-6},
%  Owner                    = {UPS},
%  Timestamp                = {2016.12.27}
%}
%
%@Article{9,
%  Title                    = {{Vision-based pedestrian detection: the PROTECTOR system}},
%  Author                   = {Gavrila, D.M. and Giebel, J. and Munder, S.},
%  Journal                  = {IEEE Intelligent Vehicles Symposium, 2004},
%  Year                     = {2004},
%  Pages                    = {13--18},
%
%  Abstract                 = { This paper presents the results of the first large-scale field tests on vision-based pedestrian protection from a moving vehicle. Our PROTECTOR system combines pedestrian detection, trajectory estimation, risk assessment and driver warning. The paper pursues a "system approach" related to the detection component. An optimization scheme models the system as a succession of individual modules and finds a good overall parameter setting by combining individual ROCs using a convex-hull technique. On the experimental side, we present a methodology for the validation of the pedestrian detection performance in an actual vehicle setting. We hope this test methodology to contribute towards the establishment of benchmark testing, enabling this application to mature. We validate the PROTECTOR system using the proposed methodology and present interesting quantitative results based on tens of thousands of images from hours of driving. Although results are promising, more research is needed before such systems can be placed at the hands of ordinary vehicle drivers.},
%  Doi                      = {10.1109/IVS.2004.1336348},
%  File                     = {:C$\backslash$:/Users/UPS/Desktop/mobile{\_}robot/9{\_}Vision based pedestrian detection the PROTECTOR system.pdf:pdf},
%  ISBN                     = {0-7803-8310-9},
%  ISSN                     = {0780383109},
%  Owner                    = {UPS},
%  Timestamp                = {2016.12.27}
%}
%
%@Article{4,
%  Title                    = {{Are we ready for Autonomous Driving? The $\backslash$textsc{\{}KITTI{\}} Vision Benchmark Suite}},
%  Author                   = {Geiger, Andreas and Lenz, Philip and Urtasun, Raquel},
%  Journal                  = {Computer Vision and Pattern Recognition},
%  Year                     = {2012},
%  Pages                    = {3354--3361},
%
%  File                     = {:C$\backslash$:/Users/UPS/Desktop/mobile{\_}robot/4{\_}Are we ready for autonomous driving.pdf:pdf},
%  ISBN                     = {9781467312288},
%  Owner                    = {UPS},
%  Timestamp                = {2016.12.27}
%}
%
%@Article{10,
%  Title                    = {{Pedestrian detection for driving assistance systems: single-frame classification and system level performance}},
%  Author                   = {Shashua, a. and Gdalyahu, Y. and Hayun, G.},
%  Journal                  = {IEEE Intelligent Vehicles Symposium, 2004},
%  Year                     = {2004},
%  Pages                    = {1--6},
%
%  Abstract                 = {We describe the functional and architectural breakdown of a monocular pedestrian detection system. We describe in detail our approach for single-frame classification based on a novel scheme of breaking down the class variability by repeatedly training a set of relatively simple classifiers on clusters of the training set. Single-frame classification performance results and system level performance figures for daytime conditions are presented with a discussion about the remaining gap to meet a daytime normal weather condition production system.},
%  Doi                      = {10.1109/IVS.2004.1336346},
%  File                     = {:C$\backslash$:/Users/UPS/Desktop/mobile{\_}robot/10{\_}Pedestrian detection for driving assistance systems.pdf:pdf},
%  ISBN                     = {0-7803-8310-9},
%  Owner                    = {UPS},
%  Timestamp                = {2016.12.27}
%}


@book{1,
	author = "Yeung, Michael and Sala, Evis and Schönlieb, Carola Bibiane and Rundo, Leonardo",
	title = "Unified Focal loss: Generalising Dice and cross entropy-based losses to handle class imbalanced medical image segmentation",
	publisher = "Computerized Medical Imaging and Graphics",
	pages = "95",
	year = 2022
}

@article{2,
	author = "Krizhevsky, A. and Sutskever, I. and Hinton",
	title = "Imagenet classification with deep convolutional neural network",
	journal = "Advances in Neural Information Processing Systems",
	pages = "1097--1105",
	year = 2012
}

@book{3,
	author = "K. Simonyan and A. Zisserman",
	title = "Very Deep Convolutional Networks for Large-Scale Image Recognition",
	month = sep,
	year = 2014
}

@article{4,
	author = "M., Sajjad and S., Khan and K., Muhammad and W., Wu and A., Ullah and S. W., Baik",
	title = "Multi-grade brain tumor classification using deep CNN with extensive data augmentation",
	journal = "J Comput Sci",
	volume = "30",
	year = 2019
}

@book{5,
	author = "Boden, Margaret A",
	title = "Inteligencia artificial",
	publisher = "Madrid: Turner",
	year = 2017
}

@book{6,
	author = "Turing, A. M.",
	title = "Computing Machinery and Intelligence",
	publisher = "Mind 49",
	pages = "433--460",
	year = 1950
}

@article{7,
	author = "Exp{\'{o}}sito Gallardo, Mar{\'{i}}a del Carmen and {\'{A}}vila {\'{A}}vila, Rafael",
	title = "Aplicaciones de la inteligencia artificial en la Medicina: perspectivas y problemas",
	journal = "Acimed",
	volume = "17",
	number = "5",
	pages = "0--0",
	year = 2008
}

@article{8,
	author = "Sarvamangala, Kulkarni, DR and V, Raghavendra",
	title = "Convolutional neural networks in medical image understanding: a survey",
	journal = "Evolutionary intelligence",
	volume = "15",
	number = "1",
	pages = "1--22",
	year = 2022
}

@article{9,
	author = "Lugo-Reyes, Sa{\'{u}}l Oswaldo and Maldonado-Col{\'{i}}n, Guadalupe and Murata, Chiharu",
	title = "Inteligencia artificial para asistir el diagnstico cl{\'{i}}nico en medicina",
	journal = "Revista Alergia M{\'{e}}xico",
	volume = "61",
	number = "2",
	pages = "110--120",
	year = 2014
}

@article{10,
	author = "Sarvamangala, DR and Kulkarni, Raghavendra V",
	title = "Convolutional neural networks in medical image understanding: a survey",
	journal = "Evolutionary intelligence",
	volume = "15",
	number = "1",
	pages = "1--22",
	year = 2022
}

@book{11,
	author = "Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and Berg, Alexander C. and Fei-Fei., Li",
	title = "Desaf{\'{i}}o de reconocimiento visual a gran escala de ImageNet.",
	publisher = "IJCV",
	year = 2015
}

@article{12,
	author = "Raja, Shanmugam, J and Pitchai, P and R",
	title = "An automated early detection of glaucoma using support vector machine based visual geometry group 19 (VGG-19) convolutional neural network",
	journal = "Wireless Personal Communications",
	volume = "118",
	pages = "523--534",
	year = 2021
}

@article{13,
	author = "Shah, Syed Rehan and Qadri, Salman and Bibi, Hadia and Shah, Syed Muhammad Waqas and Sharif, Muhammad Imran and Marinello, Francesco",
	title = "Comparing Inception V3, VGG 16, VGG 19, CNN, and ResNet 50: A Case Study on Early Detection of a Rice Disease",
	journal = "Agronomy",
	volume = "13",
	number = "6",
	pages = "1633",
	year = 2023
}

@article{14,
	author = "Cuenca, Roberto",
	title = "La g{\'{e}}nesis del uso de las radiaciones en la medicina",
	journal = "Colombia M{\'{e}}dica",
	volume = "28",
	number = "1",
	pages = "34--41",
	year = 1997
}

@article{15,
	author = "Villafuerte, Mercedes Rodr{\'{i}}guez and Mart{\'{i}}nez-D{\'{a}}valos, Arnulfo",
	title = "El uso de los rayos X en la medicina",
	journal = "Bolet{\'{i}}n de la Sociedad Mexicana de F{\'{i}}sica",
	volume = "9",
	number = "4",
	pages = "213--218",
	year = 1995
}

@book{16,
	author = "Alcaraz Baños, M and Gmez Moraga, A and Dato Gmez, MJ and Navarro, JL and Canteras Jornada, M",
	title = "Efecto genotxico inducido por la exposicin a rayos X durante exploraciones complejas de radiodiagnstico m{\'{e}}dico",
	publisher = "Oncolog{\'{i}}a (Barc.)",
	pages = "159--168",
	year = 2002
}

@article{17,
	author = "Haq, Ejaz Ul; Jianjun, Huang; Li, Kang; Haq, Hafeez Ul; Zhang, Tijiang",
	title = "An MRI-based deep learning approach for efficient classification of brain tumors",
	journal = "Journal of Ambient Intelligence and Humanized Computing",
	volume = "14",
	number = "6",
	pages = "6697--6718",
	year = 2023
}
%
%@article{18,
%	author = "M. A. Morid and A. Borjali and G. Del Fiol",
%	title = "A scoping review of transfer learning research on medical image analysis using {ImageNet}",
%	journal = "Computers in Biology and Medicine",
%	volume = "128",
%	year = 2021
%}
%
%@incollection{19,
%	author = "H. Krizhevsky and A., Sutskever and I.",
%	title = ""�Imagenet classification with deep convolutional neural network�",
%	booktitle = "Advances in Neural Information Processing Systems",
%	pages = "1097--1105",
%	year = 2012
%}
%
%@article{20,
%	author = "Y. Hu and X. Zhang and J. Yang and S. Fu",
%	title = "A Hybrid Convolutional Neural Network Model Based on Different Evolution for Medical Image Classification",
%	journal = "Engineering Letters",
%	volume = "30",
%	number = "1",
%	year = 2022
%}
%
%@article{21,
%	author = "S. A. Suha and M. N. Islam",
%	title = "An extended machine learning technique for polycystic ovary syndrome detection",
%	journal = "Scientific Reports",
%	volume = "12",
%	number = "1",
%	year = 2022
%}
%
%@article{22,
%	author = "S. S. Roy and A. Paramane and J. Singh and S. Chatterjee and A. K. Das",
%	title = "Accurate Sensing of Insulator Surface Contamination Using Customized Convolutional",
%	journal = "IEEE Sensors Letters",
%	volume = "7",
%	number = "1",
%	year = 2023
%}
%
%@article{23,
%	author = "P. P. Malla and S. Sahu and A. I. Alutaibi",
%	title = "Classification of Tumor in Brain {MR} Images Using Deep Convolutional Neural Network",
%	journal = "Processes",
%	volume = "11",
%	number = "3",
%	year = 2023
%}
%
%@article{24,
%	author = "V. Zilvan and A. Ramdan and A. Heryana and D. Krisnandi and E. Suryawati and R. S. Yuwana and R. B. S. Kusumo and H. F. Pardede",
%	title = "Convolutional variational autoencoder-based feature learning for automatic tea",
%	journal = "Journal of King Saud University - Computer and Information Sciences",
%	volume = "34",
%	number = "6",
%	year = 2022
%}
%
%@article{25,
%	author = "F. A. Torghabeh and Y. Modaresnia and M. M. Khalilzadeh",
%	title = "EFFECTIVENESS {OF} {LEARNING} {RATE} {IN} {DEMENTIA} {SEVERITY} {PREDICTION} {USING} {VGG}16",
%	journal = "Biomedical Engineering: Applications, Basis and Communications",
%	volume = "35",
%	number = "03",
%	year = 2023
%}
%
%@article{26,
%	author = "M. Riaz and S. M. G. Monir and R. Hasan",
%	title = "Evaluation of deep learning approaches for optical character recognition in {Urdu}",
%	journal = "Mehran University Research Journal of Engineering and Technology",
%	volume = "41",
%	number = "4",
%	year = 2022
%}
%
%@article{27,
%	author = "X. Zhou and T. Ito and R. Takayama and S. Wang and T. Hara and H. Fujita",
%	title = "First trial and evaluation of anatomical structure segmentations in 3{D} {CT} images",
%	journal = "Medical Imaging and Information Sciences",
%	volume = "33",
%	number = "3",
%	year = 2016
%}
%
%@book{28,
%	author = "S. Prasher and L. Nelson",
%	title = "Follicle Prediction for Polycystic Ovary Syndrome Diagnosis from Ovarian Ultrasound",
%	publisher = "Proceedings of the 17th {INDIACom}; 2023 10th International Conference on",
%	year = 2023
%}
%
%@article{29,
%	author = "J. Yao and J. Liu and Y. Zhang and H. Wang",
%	title = "Identification of winter wheat pests and diseases based on improved convolutional",
%	journal = "Open Life Sciences",
%	volume = "18",
%	number = "1",
%	year = 2023
%}
%
%@book{30,
%	author = "Z. Rui and C. Ying and W. Fangzhe and B. Xintong and T. T. Toe",
%	title = "Image Classification for Pneumonia and the Normal Based on Convolutional Neural",
%	publisher = "2023 {IEEE} 2nd International Conference on Electrical Engineering, Big Data",
%	year = 2023
%}
%
%@article{31,
%	author = "T. Banda and B. Y. W. Jie and A. A. Farid and C. S. Lim",
%	title = "Machine Vision and Convolutional Neural Networks for Tool Wear Identification and",
%	journal = "Lecture Notes in Electrical Engineering",
%	volume = "730",
%	year = 2022
%}
%
%@article{32,
%	author = "M. Sajjad and S. Khan and K. Muhammad and W. Wu and A. Ullah and S. W. Baik",
%	title = "Multi-grade brain tumor classification using deep {CNN} with extensive data",
%	journal = "Journal of Computational Science",
%	volume = "30",
%	year = 2019
%}
%
%@article{33,
%	author = "J. Mahadeokar and G. Pesavento",
%	title = "Open Sourcing a Deep Learning Solution for Detecting {NSFW} Images",
%	journal = "Yahoo Engineering",
%	volume = "24",
%	year = 2016
%}
%
%@article{34,
%	author = "A. N. A. Thohari and L. Triyono and I. Hestiningsih and B. Suyanto and A. Yobioktobera",
%	title = "Performance Evaluation of Pre-Trained Convolutional Neural Network Model for Skin",
%	journal = "JUITA: Jurnal Informatika",
%	volume = "10",
%	number = "1",
%	year = 2022
%}
%
%@article{35,
%	author = "Y. Zhang and L. Zhang",
%	title = "SGooTY: A Scheme Combining the {GoogLeNet}-Tiny and {YOLOv}5-CBAM Models for N�shu",
%	journal = "Electronics",
%	volume = "12",
%	number = "13",
%	year = 2023
%}
%
%@article{36,
%	author = "B.",
%	title = "Taşar, "{SkinCancerNet}: {Automated} {Classification} of {Skin} {Lesion} {Using} {Deep} {Transfer} {Learning}, " {Traitement} du {Signal}",
%	volume = "40",
%	number = "1",
%	year = 2023
%}
%
%@article{37,
%	author = "H. Ke and D. Chen and X. Li and Y. Tang and T. Shah and R. Ranjan",
%	title = "Towards Brain Big Data Classification: Epileptic {EEG} Identification with a",
%	journal = "IEEE Access",
%	volume = "6",
%	year = 2018
%}
%
%@article{38,
%	author = "H. Xu and T. Tang",
%	title = "Two-phase flow pattern online monitoring system based on convolutional neural",
%	journal = "Nuclear Engineering and Technology",
%	volume = "54",
%	number = "12",
%	year = 2022
%}
%
%@article{39,
%	author = "Purwono, A. Ma�arif and W. Rahmaniar and H. I. K. Fathurrahman and A. Z. K. Frisky and Q. M. U. Haq",
%	title = "Understanding of Convolutional Neural Network ({CNN}): A Review",
%	journal = "International Journal of Robotics and Control Systems",
%	volume = "2",
%	number = "4",
%	year = 2022
%}
%
%@article{40,
%	author = "M. Yeung and E. Sala and C. B. Sch�nlieb and L. Rundo",
%	title = "Unified {Focal} loss: {Generalising} {Dice} and cross entropy-based losses to handle",
%	journal = "Computerized Medical Imaging and Graphics",
%	volume = "95",
%	year = 2022
%}